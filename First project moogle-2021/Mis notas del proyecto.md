# Mis notas del proyecto üíª

------

## Preliminares üìù:

Para una mejor implementaci√≥n del proyecto, se hizo necesaria las investigaci√≥n de algoritmos, patrones y  estructuras de datos que facilitaran y optimizaran de alguna manera el prop√≥sito del proyecto.

Se utilizan estructuras destinadas a un manejo m√°s c√≥modo de los datos, tales como las Listas y Diccionarios, aprovechando las ventajas que brindan, entre otros, para a√±adir y eliminar elementos de una colecci√≥n con mayor facilidad de la que nos brindan los array, o la relaci√≥n que nos permite establecer en una misma estructura entre una llave y un valor.

Tambi√©n hago uso de las maneras m√°s simples de estructuras, tales como expresiones lambda para complementar algunos m√©todos de clases contenidas en `System` , como la clase `Enumerable`. El siguiente ejemplo determina si alg√∫n elemento `x` de una Lista `List<string> terms` satisface una condici√≥n `x == "~"` .

```c#
terms.Any(x => x == "~")
```



## La ideaüí°: 

La idea general del proyecto es un motor de b√∫squeda que se basa en una colecci√≥n de documentos para responder a una consulta del usuario, de manera que los documentos deben ser archivos de tipo `.txt` y con Encoding UTF-8. El proyecto sigue la idea de *Singleton*, como patr√≥n de dise√±o creacional, y este √∫ltimo constituye una idea que b√°sicamente se enfoca en la creaci√≥n de una clase de intancia **√∫nica**, y accesible desde cualquier otra clase de mi programa. De esta manera, una vez creada, funciona como una base de datos que contiene la informaci√≥n fundamental del Corpus que no necesita de que el usuario haya realizado el query con anterioridad.

Una vez generada √©sta base de datos, se ejecuta la interfaz visual de mi motor de b√∫squeda y es entonces donde el usuario realiza la consulta y entra en juego la otra parte del proyecto: responder a la b√∫squeda. El motor de b√∫squeda se apoya en el **modelo de espacio vectorial** de los sistemas de recuperaci√≥n de informaci√≥n y en la estad√≠stica de puntuaci√≥n y evaluaci√≥n **TF-IDF**. Para un entendimiento m√°s preciso del funcionamiento del motor, se abordar√° con m√°s detalle en la pr√≥xima secci√≥n.



## Los detalles de la implementaci√≥nüë®‚Äçüíª: 

Aparece por secciones donde hago referencia a las clases del proyecto y las partes fundamentales de la composici√≥n de mi c√≥digo.



#### CorpusDB: "Mi clase Singleton"

La clase `CorpusDB` es la clase de instancia √∫nica que se encargar√° de reunir la informaci√≥n del Corpus, y siguiendo la idea de *Singleton*, funciona como variable de acceso global al resto de mis clases. Para su correcto funcionamiento, contiene una variable encargada de instanciar la clase desde ella misma, esto debido a que el constructor es privado, precisamente para evitar que se acceda a √©l y se cree otra instancia de la clase. Adem√°s tiene una propiedad p√∫blica encargada de copiar la instancia cada vez que se desee acceder a la clase. 

La clase como funci√≥n de base de datos, se encarga de crear una serie de propiedades previas a la realizaci√≥n de la consulta, bas√°ndose en el Corpus de los documentos. Con su instanciaci√≥n recorre cada documento de la carpeta `Content`, de los cuales recopila informaci√≥n tal como: una lista con los string que representan todas las palabras que existen en mi base de datos de documentos, o el Diccionario que, a cada documento, le asigna otro Diccionario con las palabras como *key*, y la frecuencia con que aparecen en el documento como *value*.

Esta clase es llamada desde `MoogleServer`, desde la clase `Program.cs`, justo antes de ejecurase el llamado a que se ejecute la aplicaci√≥n de mi programa. Tras la ejecuci√≥n del programa se abre la interfaz visual de pa aplicaci√≥n y es doende el usuario se dispone a realizar la consulta.



#### Moogle class:

La clase est√°tica `Moogle` es la que contiene al m√©todo `Query`, este m√©todo es el que se ejecuta una vez el usuario hace la consulta, y como es l√≥gico, recibe la consulta del mismo. Este m√©todo forma una estructura casi lineal donde cada llamado necesita de los anteriores. Por ese m√©todo pasan todos los llamados desde la misma introducci√≥n del query, hasta la salida de los resultados de b√∫squeda. 

![](QueryDiagram.jpg)



#### Query Analyzer:

La clase de instancia `InputQuery`,  va a instanciarse una vez el usuario haya hecho una b√∫squeda, su constructor ser√° llamado desde el m√©todo `Moogle.Query`. Esta clase es la encargada de analizar la consulta del usuario y crear√° un objeto de su tipo que contiene toda la informaci√≥n de sus t√©rminos para la b√∫squeda por el motor. Teniendo en cuenta los operadores de b√∫squeda, separa los t√©rminos en Listas en dependencia de su objetivo en la b√∫squeda (las que **deben** aparecer en el documento de salida, las que tienen alg√∫n nivel de importancia, etc, as√≠ como una lista con todas las palabras de mi query)



#### Stop & Needed Docs:

En esta secci√≥n se separan en arrays los documentos que contienen a las palabras con los operadores `!` & `^`, para posteriormente tenerlos en cuenta a la hora de escoger los documentos a devolver. Esto queda m√°s detallado en la secci√≥n dedicada a los operadores.



#### TF-IDF Scorer:

Esta es la parte donde se genera la matriz de los TF-IDF de las palabras del query, respecto a los documentos. El TF-IDF nos da una medida de cu√°n relevante es una palabra para un documento, en una colecci√≥n de documentos. Por tanto cada palabra tendr√≠a su puntuaci√≥n. Existen varias formas de calcular esta medida, la que se utiliza es la propuesta a continuaci√≥n, pero primero separemos este concepto en dos partes:

**Term Frequency**(TF): Para ello hemos tomado una frecuencia normalizada, la cual se calcula dividiendo la frecuencia bruta de la palabra en el documento $(n)$, entre la frecuencia m√°xima de una palabra en el documento $(m)$. Quedar√≠a: $tf = n/m$

**Inverse Document Frequency**(IDF): De manera general, expresa cu√°n rara es la palabra en un corpus de documentos, y su f√≥rmula queda expresada como el logaritmo del cociente entre, el total de documentos $(d)$ y la cantidad de documentos donde aparece la palabra $(d')$. Quedar√≠a: $log(d/d')$. Es un hecho que existen palabras que pueden no aparecer en los documento, por ello deber√≠amos tener en cuenta que la divisi√≥n entre 0 en el argumento del logaritmo se nos indefinir√≠a, para ello sumamos al denominador del cociente un valor insignificante que evite la idefinici√≥n de la expresi√≥n; en este caso fue 0.01. Ahora...¬øQu√© pasar√≠a con la base del logaritmo?¬øNos servir√≠a cualquier base?. En un principio s√≠, se podr√≠a hacer con cualquier base siempre y cuando sea la misma que se utilice en todas las palabras. Pero...una base cualquiera, har√≠a que la puntuaci√≥n que nos da el IDF nos d√© resultados en diferentes intervalos de variaci√≥n, en dependencia del tama√±o del corpus. Es decir, tomando una base $2$, para un corpus de 10 documentos los valores del IDF estar√≠an en el intervalo [0 - 3.32193]; pero si el corpus tuviera 100 elementos (dato que no ser√° fijo), entonces el intervalo ser√≠a [0 - 6.64386]. Por tanto, para un mayor control sobre el score que dejar√≠an nuestras palabras en los documentos, definimos una base para el logaritmo, en dependencia de la cantidad de documentos del corpus. Tomar√≠amos como base: la parte entera de la ra√≠z cuadrada de la cantidad de documentos del corpus $(d)$. Quedar√≠a: $base = Truncate(sqrt(d))$. De esta manera definimos un intervalo [0 - 2] en el que van a quedar los valores del IDF.

**TF-IDF**: La puntuaci√≥n final quedar√≠a como el producto de los dos valores obtenidos anteriormente, de esta manera tendr√≠amos el peso de las palabras en los documentos del corpus.



#### Score Refactor:

En esta secci√≥n lo que hacemos es reevaluar los valores del TF-IDF de aquellas palabras que se vean afectadas por los operadores `*` & `~`. Los detalles de como punt√∫an los operadores se analizan luego en la secci√≥n dedicada a los mismos.



#### Docs Scorer:

Para evaluar el ranking de los documentos, teniendo la matriz de los TF-IDF de todas sus palabras, he opatado por una v√≠a m√°s intuitiva. Simplemente definiremos el score de cada documento como la suma de los valores del TF-IDF de todas las palabras del query que en √©l aparecen. Algo tan sencillo como sumar todos los elementos de una columna de una matriz.



#### Return Docs:

Lo primero que debemos tener en cuenta en esta secci√≥n es identificar a aquellos documentos que con anterioridad marcamos como *Stop & Needed Docs*, y realizar las acciones que hagan que se cumplan los prop√≥sitos de los operadores. 

En un segundo momento deber√≠amos ordenar los documentos en dependencia del score calculado de los mismos en la secci√≥n anterior. Para ello tenemos el m√©todo `SortTill`, que los va ordenando hasta que llegue el punto en que los scores de los documenos resultantes sean menores que un valor predefinido(0.1) que nos indica un punto relativo donde los documentos ya no tienen relevancia alguna. En dependencia de lo anterior, ahora tocar√≠a decidir cuantos documentos vamos a devolver como resultado de la b√∫squeda. Para ello, tomaremos como m√°ximo 10 resultados, por lo que si la lista que tiene nuestros posibles documentos a devolver tiene m√°s de esta cantidad, no quedar√≠amos solo con los 10 de m√°s alto score; en el caso contrario, nos los quedar√≠amos todos.



#### Suggestions:

El algoritmo analiza cada una de las palabras del query en busca de aquellas que, quiz√°s por error de escritura no aparezcan en ning√∫n documento del corpus o que sean pr√°cticamente irrelevantes para todos los documentos. √âsta irrelevancia viene dada por un valor por defecto de 0.1f, de esta manera se intentar√° buscar una suggerencia para las palabras que resulten irrelevantes en el corpus.

Entonces para cada una de las palabras analizaremos mediante el algoritmo de la Distancia de Leveishtein, las distancia a la que est√°n de la original, pero no analizaremos todas las palabras, sino solo las que tengan un tama√±o relativamente cercano (2 caracteres m√°s y 2 menos). Luego guardar√≠amos en una lista todas las palabras que tengan la menor distancia encontrada. A√∫n tenemos varias palabras, as√≠ que para escoger una, me quedar√© con la palabra que m√°s relevante resulte para el corpus, siempre y cuando tenga un score superior a 0.1f, de esta manera aseguramos que la sugerencia que se proponga **"en la mayor√≠a de los casos"**, tenga resultados en la b√∫squeda.

En el caso en que no tenga ninguna sugerencia, devolver√≠a un valor arbitrario que luego ser√° detectado a la hora de imprimir el suggestion en pantalla.



#### Snippet:

El snippet consiste en un fragmento del texto, en el que aparece al menos una parte de la consulta del usuario, en los textos del corpus. Esto nos permite una visualizaci√≥n previa del contenido del texto, antes de acceder al documento en s√≠. Para escoger qu√© fragmento devolver, decidimos primero qu√© palabra de la consulta del usuarios es en realidad m√°s relevante. Para ello usaremos los valores calculados previamente de los TF-IDF de las palabras del query, entonces, sumando los valores de toda la fila, obtendremos por cada palabra, un valor que las identifica con el resto en cuando a relevancia en el corpus. Teniendo lo anterior, podemos ordenar las palabras por ese valor de relevancia, y entonces extraer para el snippet de cada documento, la palabra m√°s relevante que est√© contenida en √©l.

Teniendo la palabra y el texto donde buscarla, ¬øcon qu√© fragmento nos quedar√≠amos?. Primero lo que hacemos es separar el texto en oraciones, y entonces tomar√≠amos para devolver la primera oraci√≥n donde aparece la palabra que queremos mostrar. Para evitar textos tan largos, si la oraci√≥n excede de las 30 palabras lo que har√≠amos es quedarnos con las 15 palabras anteriores y las 15 posteriores a la ubicaci√≥n de mi palabra, siempre que no nos salgamos de la oraci√≥n.



#### SearchResult:

Teniendo ya todo lo que necesitamos devolver al usuario, vamos a convertir cada documento a devolver, en un objeto de tipo `SearchItem`, pas√°ndole al constructor como par√°metros: el t√≠tulo, el snippet y el score de los documentos a devolver. Estos `SearchItem` los tendremos en una colecci√≥n, la cual servir√°, junto con la sugerencia antes generada, como par√°metro de la clase `SearchResult`. Esta √∫ltima ser√° el retorno del m√©todo `Query`. A partir de este punto solo quedar√≠a que la interfaz interprete la clase y la muestre al usuario.



#### Los operadores:

Para un manejo m√°s personalizado de la b√∫squeda por parte del usuario, he implementado una serie de operadores v√°lidos que influyen directamente en los resultados:

El operador: Stop Word `!`. Las palabras que vengan precedidas por este operador, har√° que los documentos en las que aparezcan, no sean devueltos por el motor de b√∫squeda. ¬øC√≥mo queda implementado?. Durante el tiempo de ejecuci√≥n de mi m√©todo principal `Query`, se llama al m√©todo `Engine.GetStopOrNeededDocuments`, este m√©todo es el encargado de recorrer cada palabra ya previamente detectada como Stop Word, y devolver un array con las rutas correspondientes a los documentos donde aparecen dichas palabras. Este array es pasado luego a un m√©todo que decide cu√°les documentos devolver.

El operador: Needed Word `^`. Las palabras que vengan precedidas por este operador, har√° que los documentos en las que aparezcan, sean necesariamente devueltos por el motor de b√∫squeda. ¬øLa implementaci√≥n?. Exactamente como ocurre con el operador anterior, se llama al mismo m√©todo que genera de nuevo un array, esta vez con los documentos que contienen las palabras que necesariamente deben estar en ellos al devolverlos.

El operador: Relevant Word `*`. Las palabras precedidas por este operador tienen una relevancia diferente a las palabras ordinarias del query, por tanto el score de las mismas se reeval√∫a en la matriz de los TF-IDF. De esta manera, se multiplica el valor del score obtenido del TF-IDF por la cantidad de estrellas de relevancia de la palabra.

El operador: Related Words `~`. Este operador intermedio entre dos palabras es el ancargado de aumentar el score de las palabras que, por desici√≥n del usuario que hace el query, deber√≠an importar m√°s mientras m√°s cercanas est√©n.  Para este operador apoyamos de un c√°lculo con ayuda del an√°lisis matem√°tico. Para ello he decidido y concluido que: dos palabras en un documento no van a estar realmente relacionadas hasta que est√©n los suficientemente cerca una de la otra, respetando el orden en que aparecen.

<img src="Gr√°fica_f(x).jpg" style="zoom:25%;" /><img src="f(x).jpg" style="zoom: 50%;" /><img src="x.jpg" style="zoom: 45%;" />

 De esta manera, las im√°genes muestran la funci√≥n $f(x)$, de la cu√°l solo nos resulta de inter√©s el intervalo continuo $[0, 1]$. Esta funci√≥n recibe el par√°metro $x$, que representa la cercan√≠a de las palabras en el documento. $x$, est√° definida como el cociente de la cantidad de palabras que est√°n entre ellas: $(n)$, con la cantidad m√°xima de palabras que puede haber entre ellas, o sea, la cantidad de palabras del documento: $(t)$. A continuaci√≥n algunos ejemplos de evaluaciones para entender mejor los resultados.

- Caso extremo palabras distantes:  $x = t /t$   =>   $f(x) = 0$
- Caso extremo palabras cercanas:  $x = 0/t$   =>   $f(x) = 1$
- Caso 1/4 de distancia:  $x = (t/4)/t$   =>   $f(x) = 0,0023$  *aprox*
- Caso 1/50 de distancia:  $x=(t/50)/t$   =>   $f(x) = 0,6542 $ *aprox*

Tambi√©n podemos observar que mientras m√°s largo el documento, m√°s punt√∫a si est√°n a la misma distancia

- Caso $f(1/10) = 0,10$
- Caso $f(1/100) = 0.81$
- Caso $f(1/1000) = 0,98$

La forma en que se eval√∫a el score de este operador consiste en llevar la sumatoria de las evaluaciones de $f(x)$ por cada vez que se encuentre el par en el documento. Luego este score ser√° dividido en 2 mitades, las cuales ser√°n sumdas directamente a los TF-IDF de las dos palabras relacionadas en el propio documento.

Ambos √∫ltimos 2 operadores toman efecto tras el llamado del m√©todo `Scorer.ScoreOperators`, encargado de refactorizar los TF-IDF de las palabras en correspondencia con los criterios de los operadores.



## Bibliograf√≠a:

https://es.wikipedia.org/wiki/Singleton

https://refactoring.guru/es/design-patterns/singleton

https://sites.google.com/site/algoritmossimilaridaddistancia/distancia-de-levenshtein

https://es.wikipedia.org/wiki/Modelo_de_espacio_vectorial

https://es.wikipedia.org/wiki/Tf-idf

